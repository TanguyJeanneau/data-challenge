{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Copie de Hand_Gesture_Recognition.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SknZDgonQEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yngHaFny5380",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d5ae47c9-810a-4cf4-952c-2e0055b73d84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCjpM56n3A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import misc\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "def read_csv_infos(file):\n",
        "\n",
        "\tidx = []\n",
        "\tlabels = []\n",
        "\tsizesequences = []\n",
        "\n",
        "\twith open(file, 'r') as f:\n",
        "\t\tdata = csv.reader(f, delimiter=' ')\n",
        "\t\tfor d in data:\n",
        "\t\t\tj = d[0].split(',')\n",
        "\t\t\tidx.append(int(j[0]))\n",
        "\t\t\tlabels.append(int(j[1]))\n",
        "\t\t\tsizesequences.append(int(j[2]))\n",
        "\n",
        "\treturn idx, labels, sizesequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc4ugSh_n-eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_csv_skeleton(file, dim_joints):\n",
        "\n",
        "\tn = []\n",
        "\tn_samples = 0\n",
        "\tn_frames = 0\n",
        "\twith open(file, 'r') as f:\n",
        "\t\tdata = csv.reader(f, delimiter=' ')\n",
        "\t\tfor d in data:\n",
        "\t\t\tn_samples += 1\n",
        "\t\t\tn_frames=0\n",
        "\t\t\tfor j in d[0].split(','):\n",
        "\t\t\t\tn.append(float(j))\n",
        "\t\t\t\tn_frames += 1\n",
        "    # convert data in numpy array\n",
        "\tn = np.asarray(n)\n",
        "\tn = np.reshape(n, (n_samples, n_frames//(22*dim_joints), 22, dim_joints))\n",
        "\treturn n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czs7dFI_nQEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skeletons2=read_csv_skeleton(\"/content/drive/My Drive/data/skeletons_image_train.csv\",2)\n",
        "idx, labels, sequences=read_csv_infos(\"/content/drive/My Drive/data/infos_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yAxwbkMnQE0",
        "colab_type": "code",
        "outputId": "865128f3-ad42-4802-8f33-222262ad7bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skeletons2.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1960, 171, 22, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddSYn3ZnQE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "skeletons3=read_csv_skeleton(\"/content/drive/My Drive/data/skeletons_world_train.csv\",3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WKYQoTKnQE8",
        "colab_type": "code",
        "outputId": "d2226058-5274-4cca-c621-374510e5f6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "skeletons3.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1960, 171, 22, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcB9kcgonQFA",
        "colab_type": "code",
        "outputId": "c552abda-b8c1-4cb3-952c-421905d83c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout,Flatten, Dense, LeakyReLU\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
        "          input_shape=(171,22,3), activation='relu'))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dense(29, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 171, 22, 32)       896       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 171, 22, 64)       18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 85, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 85, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 85, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 83, 9, 256)        295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 27, 3, 256)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 27, 3, 256)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 20736)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               5308672   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 29)                7453      \n",
            "=================================================================\n",
            "Total params: 5,770,333\n",
            "Trainable params: 5,770,333\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw3tIjcpnQFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4HgB_QfnQFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyjxMtQJvU1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x=skeletons3\n",
        "n=x.shape[0]\n",
        "y=labels\n",
        "selection=np.arange(n)\n",
        "np.random.shuffle(selection)\n",
        "subselection=selection[:int(n*0.6)]\n",
        "x_train=x[subselection]\n",
        "x_test=x[[i for i in np.arange(n) if i not in subselection]]\n",
        "y_train=y[subselection]\n",
        "y_test=y[[i for i in np.arange(n) if i not in subselection]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxnCpQz7nQFJ",
        "colab_type": "code",
        "outputId": "7c1edb95-9933-4c68-8776-5fc5cf942c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "         epochs=100,\n",
        "          batch_size=64#,\n",
        "          #validation_data=(x_test, y_test)\n",
        "         )"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1960/1960 [==============================] - 3s 1ms/step - loss: 3.2412 - acc: 0.0679\n",
            "Epoch 2/100\n",
            "1960/1960 [==============================] - 2s 956us/step - loss: 2.9466 - acc: 0.1158\n",
            "Epoch 3/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 2.5601 - acc: 0.2071\n",
            "Epoch 4/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 2.1233 - acc: 0.3245\n",
            "Epoch 5/100\n",
            "1960/1960 [==============================] - 2s 976us/step - loss: 1.7707 - acc: 0.4281\n",
            "Epoch 6/100\n",
            "1960/1960 [==============================] - 2s 968us/step - loss: 1.5672 - acc: 0.4786\n",
            "Epoch 7/100\n",
            "1960/1960 [==============================] - 2s 969us/step - loss: 1.3976 - acc: 0.5505\n",
            "Epoch 8/100\n",
            "1960/1960 [==============================] - 2s 975us/step - loss: 1.2413 - acc: 0.5913\n",
            "Epoch 9/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 1.1501 - acc: 0.6214\n",
            "Epoch 10/100\n",
            "1960/1960 [==============================] - 2s 957us/step - loss: 1.1017 - acc: 0.6464\n",
            "Epoch 11/100\n",
            "1960/1960 [==============================] - 2s 963us/step - loss: 1.0183 - acc: 0.6628\n",
            "Epoch 12/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 0.9129 - acc: 0.6872\n",
            "Epoch 13/100\n",
            "1960/1960 [==============================] - 2s 973us/step - loss: 0.9217 - acc: 0.6781\n",
            "Epoch 14/100\n",
            "1960/1960 [==============================] - 2s 969us/step - loss: 0.8101 - acc: 0.7291\n",
            "Epoch 15/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.7053 - acc: 0.7551\n",
            "Epoch 16/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.6539 - acc: 0.7852\n",
            "Epoch 17/100\n",
            "1960/1960 [==============================] - 2s 971us/step - loss: 0.6316 - acc: 0.7837\n",
            "Epoch 18/100\n",
            "1960/1960 [==============================] - 2s 974us/step - loss: 0.6346 - acc: 0.7903\n",
            "Epoch 19/100\n",
            "1960/1960 [==============================] - 2s 975us/step - loss: 0.5372 - acc: 0.8117\n",
            "Epoch 20/100\n",
            "1960/1960 [==============================] - 2s 973us/step - loss: 0.5239 - acc: 0.8214\n",
            "Epoch 21/100\n",
            "1960/1960 [==============================] - 2s 967us/step - loss: 0.4873 - acc: 0.8423\n",
            "Epoch 22/100\n",
            "1960/1960 [==============================] - 2s 962us/step - loss: 0.5255 - acc: 0.8235\n",
            "Epoch 23/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.4581 - acc: 0.8449\n",
            "Epoch 24/100\n",
            "1960/1960 [==============================] - 2s 971us/step - loss: 0.4385 - acc: 0.8474\n",
            "Epoch 25/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 0.3825 - acc: 0.8663\n",
            "Epoch 26/100\n",
            "1960/1960 [==============================] - 2s 963us/step - loss: 0.3855 - acc: 0.8730\n",
            "Epoch 27/100\n",
            "1960/1960 [==============================] - 2s 960us/step - loss: 0.3615 - acc: 0.8796\n",
            "Epoch 28/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 0.3267 - acc: 0.8867\n",
            "Epoch 29/100\n",
            "1960/1960 [==============================] - 2s 971us/step - loss: 0.3368 - acc: 0.8811\n",
            "Epoch 30/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.2948 - acc: 0.9036\n",
            "Epoch 31/100\n",
            "1960/1960 [==============================] - 2s 968us/step - loss: 0.3072 - acc: 0.8959\n",
            "Epoch 32/100\n",
            "1960/1960 [==============================] - 2s 962us/step - loss: 0.3270 - acc: 0.8821\n",
            "Epoch 33/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 0.3126 - acc: 0.8959\n",
            "Epoch 34/100\n",
            "1960/1960 [==============================] - 2s 971us/step - loss: 0.3588 - acc: 0.8847\n",
            "Epoch 35/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.2760 - acc: 0.9148\n",
            "Epoch 36/100\n",
            "1960/1960 [==============================] - 2s 971us/step - loss: 0.2734 - acc: 0.9138\n",
            "Epoch 37/100\n",
            "1960/1960 [==============================] - 2s 959us/step - loss: 0.2427 - acc: 0.9179\n",
            "Epoch 38/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.2428 - acc: 0.9143\n",
            "Epoch 39/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.2403 - acc: 0.9163\n",
            "Epoch 40/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 0.1944 - acc: 0.9306\n",
            "Epoch 41/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.1841 - acc: 0.9260\n",
            "Epoch 42/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.2025 - acc: 0.9337\n",
            "Epoch 43/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.1937 - acc: 0.9378\n",
            "Epoch 44/100\n",
            "1960/1960 [==============================] - 2s 969us/step - loss: 0.1965 - acc: 0.9321\n",
            "Epoch 45/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.1914 - acc: 0.9352\n",
            "Epoch 46/100\n",
            "1960/1960 [==============================] - 2s 969us/step - loss: 0.1889 - acc: 0.9434\n",
            "Epoch 47/100\n",
            "1960/1960 [==============================] - 2s 971us/step - loss: 0.2229 - acc: 0.9209\n",
            "Epoch 48/100\n",
            "1960/1960 [==============================] - 2s 963us/step - loss: 0.2030 - acc: 0.9245\n",
            "Epoch 49/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.1924 - acc: 0.9352\n",
            "Epoch 50/100\n",
            "1960/1960 [==============================] - 2s 959us/step - loss: 0.1906 - acc: 0.9332\n",
            "Epoch 51/100\n",
            "1960/1960 [==============================] - 2s 972us/step - loss: 0.1713 - acc: 0.9429\n",
            "Epoch 52/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 0.1258 - acc: 0.9597\n",
            "Epoch 53/100\n",
            "1960/1960 [==============================] - 2s 962us/step - loss: 0.2049 - acc: 0.9352\n",
            "Epoch 54/100\n",
            "1960/1960 [==============================] - 2s 975us/step - loss: 0.2057 - acc: 0.9240\n",
            "Epoch 55/100\n",
            "1960/1960 [==============================] - 2s 967us/step - loss: 0.1716 - acc: 0.9429\n",
            "Epoch 56/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 0.1059 - acc: 0.9663\n",
            "Epoch 57/100\n",
            "1960/1960 [==============================] - 2s 968us/step - loss: 0.1320 - acc: 0.9556\n",
            "Epoch 58/100\n",
            "1960/1960 [==============================] - 2s 955us/step - loss: 0.1549 - acc: 0.9505\n",
            "Epoch 59/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.1415 - acc: 0.9541\n",
            "Epoch 60/100\n",
            "1960/1960 [==============================] - 2s 972us/step - loss: 0.1310 - acc: 0.9571\n",
            "Epoch 61/100\n",
            "1960/1960 [==============================] - 2s 972us/step - loss: 0.1128 - acc: 0.9561\n",
            "Epoch 62/100\n",
            "1960/1960 [==============================] - 2s 974us/step - loss: 0.1537 - acc: 0.9515\n",
            "Epoch 63/100\n",
            "1960/1960 [==============================] - 2s 956us/step - loss: 0.1716 - acc: 0.9444\n",
            "Epoch 64/100\n",
            "1960/1960 [==============================] - 2s 969us/step - loss: 0.1566 - acc: 0.9480\n",
            "Epoch 65/100\n",
            "1960/1960 [==============================] - 2s 960us/step - loss: 0.1124 - acc: 0.9622\n",
            "Epoch 66/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.0836 - acc: 0.9745\n",
            "Epoch 67/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.1123 - acc: 0.9628\n",
            "Epoch 68/100\n",
            "1960/1960 [==============================] - 2s 962us/step - loss: 0.1539 - acc: 0.9587\n",
            "Epoch 69/100\n",
            "1960/1960 [==============================] - 2s 972us/step - loss: 0.1133 - acc: 0.9602\n",
            "Epoch 70/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.1102 - acc: 0.9633\n",
            "Epoch 71/100\n",
            "1960/1960 [==============================] - 2s 973us/step - loss: 0.1033 - acc: 0.9653\n",
            "Epoch 72/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.0861 - acc: 0.9684\n",
            "Epoch 73/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 0.0843 - acc: 0.9714\n",
            "Epoch 74/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 0.1286 - acc: 0.9561\n",
            "Epoch 75/100\n",
            "1960/1960 [==============================] - 2s 957us/step - loss: 0.1581 - acc: 0.9526\n",
            "Epoch 76/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.1353 - acc: 0.9587\n",
            "Epoch 77/100\n",
            "1960/1960 [==============================] - 2s 965us/step - loss: 0.1015 - acc: 0.9679\n",
            "Epoch 78/100\n",
            "1960/1960 [==============================] - 2s 963us/step - loss: 0.1098 - acc: 0.9622\n",
            "Epoch 79/100\n",
            "1960/1960 [==============================] - 2s 970us/step - loss: 0.1081 - acc: 0.9561\n",
            "Epoch 80/100\n",
            "1960/1960 [==============================] - 2s 976us/step - loss: 0.1053 - acc: 0.9668\n",
            "Epoch 81/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.0868 - acc: 0.9740\n",
            "Epoch 82/100\n",
            "1960/1960 [==============================] - 2s 960us/step - loss: 0.0913 - acc: 0.9704\n",
            "Epoch 83/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.0802 - acc: 0.9714\n",
            "Epoch 84/100\n",
            "1960/1960 [==============================] - 2s 978us/step - loss: 0.0898 - acc: 0.9714\n",
            "Epoch 85/100\n",
            "1960/1960 [==============================] - 2s 959us/step - loss: 0.0940 - acc: 0.9719\n",
            "Epoch 86/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.0960 - acc: 0.9735\n",
            "Epoch 87/100\n",
            "1960/1960 [==============================] - 2s 960us/step - loss: 0.1071 - acc: 0.9648\n",
            "Epoch 88/100\n",
            "1960/1960 [==============================] - 2s 962us/step - loss: 0.0705 - acc: 0.9776\n",
            "Epoch 89/100\n",
            "1960/1960 [==============================] - 2s 962us/step - loss: 0.1145 - acc: 0.9668\n",
            "Epoch 90/100\n",
            "1960/1960 [==============================] - 2s 956us/step - loss: 0.0963 - acc: 0.9689\n",
            "Epoch 91/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.0651 - acc: 0.9786\n",
            "Epoch 92/100\n",
            "1960/1960 [==============================] - 2s 973us/step - loss: 0.0760 - acc: 0.9745\n",
            "Epoch 93/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.0989 - acc: 0.9719\n",
            "Epoch 94/100\n",
            "1960/1960 [==============================] - 2s 956us/step - loss: 0.1083 - acc: 0.9638\n",
            "Epoch 95/100\n",
            "1960/1960 [==============================] - 2s 967us/step - loss: 0.0876 - acc: 0.9709\n",
            "Epoch 96/100\n",
            "1960/1960 [==============================] - 2s 966us/step - loss: 0.0630 - acc: 0.9786\n",
            "Epoch 97/100\n",
            "1960/1960 [==============================] - 2s 967us/step - loss: 0.0923 - acc: 0.9704\n",
            "Epoch 98/100\n",
            "1960/1960 [==============================] - 2s 958us/step - loss: 0.0885 - acc: 0.9760\n",
            "Epoch 99/100\n",
            "1960/1960 [==============================] - 2s 964us/step - loss: 0.0976 - acc: 0.9663\n",
            "Epoch 100/100\n",
            "1960/1960 [==============================] - 2s 961us/step - loss: 0.1311 - acc: 0.9551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69f9f17278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9_zNYkDnQFU",
        "colab_type": "code",
        "outputId": "ec66b117-4d70-409b-ce45-d72b56787ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784/784 [==============================] - 0s 615us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.58874727025324, 0.7219387755102041]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CjItpvKvDSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_data = read_csv_skeleton(\"/content/drive/My Drive/data/skeletons_world_test.csv\",3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EvfB8-h24ib",
        "colab_type": "code",
        "outputId": "dc1c7fd5-c1f8-4e3f-c00e-b8c8f8e32e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(evaluation_data.shape)\n",
        "print(skeletons3.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(840, 162, 22, 3)\n",
            "(1960, 171, 22, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDVmSImE3F-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "npad = ((0, 0), (0, 9), (0, 0), (0, 0))\n",
        "eval_pad = np.pad(evaluation_data, pad_width=npad, mode='constant', constant_values=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VdK0hef3LbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict_classes(eval_pad)\n",
        "results = [[i, pred[i]] for i in range(840)]\n",
        "np.savetxt(\"results_v1.csv\", results, delimiter=\",\", header='id,prediction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiTKY8Xl9hNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = np.array([int(np.floor(i/30))+1 for i in range(840)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1euURa33EMb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "80d48f16-121e-411d-f90a-40dbc0c8ff33"
      },
      "source": [
        "pred"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  9,  2,  2,  1,  1,\n",
              "       10,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
              "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
              "        8,  8,  8,  8,  8,  8,  2,  3,  3,  3,  1, 11,  3,  3,  3, 11,  5,\n",
              "        3,  9,  3,  3,  3,  9, 27,  7,  1,  1,  1,  3,  7,  7,  3,  5,  7,\n",
              "        3,  5,  5,  5,  5,  7,  2, 28,  4,  4,  4, 10, 20,  4,  9,  4,  4,\n",
              "        4,  4,  8,  4,  4,  4,  4,  8,  4,  4,  4,  4,  4,  4,  4,  8,  8,\n",
              "        3,  5,  5,  5,  6,  6,  6,  6,  5,  7,  5,  5,  5,  5, 17,  9,  5,\n",
              "       17,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  4,  4,  6,  6,\n",
              "        6,  6,  4,  6,  6,  6,  6,  7,  5,  1, 18,  6, 17,  6,  6,  6,  6,\n",
              "        6,  6,  6,  6,  7,  7,  7,  8,  7,  7,  7,  7,  7,  7,  4,  6,  7,\n",
              "        7,  3,  1,  1,  1,  9,  1,  7,  1,  1,  7,  7,  7,  7,  8,  8,  8,\n",
              "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8, 10,  8,  2, 10,  8,  8,  8,\n",
              "        8,  2,  8,  2, 10, 10, 10, 10, 10,  9, 10,  9,  9, 10,  9,  9,  9,\n",
              "        9,  9, 10,  9,  9, 10,  9,  9,  9,  9,  9,  9,  9,  9,  7, 15, 10,\n",
              "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 12, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 27, 10, 10, 10, 10, 12, 12, 12, 11, 11, 11, 11, 12, 12,\n",
              "       12, 11, 11, 11, 11, 12, 11,  1,  9, 12, 11, 11, 11, 11, 11, 11,  7,\n",
              "       11, 11,  9,  7, 11, 11, 12, 12, 11, 12, 10, 11, 11, 12, 12, 12, 12,\n",
              "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13,\n",
              "       13, 13, 13, 13, 13,  9, 13, 13, 14, 14, 14, 13, 13, 13, 13, 13, 10,\n",
              "       13, 13, 13, 14, 13, 13, 13, 13, 13, 13,  5,  9, 13,  7, 10, 14, 14,\n",
              "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 14, 26, 14,\n",
              "       14, 14, 14, 14, 14, 14, 13, 14, 14, 15, 15, 15, 15, 15, 11, 11, 27,\n",
              "       15,  9, 15, 15, 27, 15, 15, 16, 15, 12, 15, 15, 15, 15, 15, 15, 15,\n",
              "       15, 16, 10, 16, 16, 16, 14, 16, 16, 16, 16, 12, 16, 16, 16, 16, 16,\n",
              "       15, 15, 16, 16, 16, 16,  8,  8,  8,  8,  8,  8, 17, 17, 17,  3, 17,\n",
              "       17, 17, 17, 17, 17, 17,  1,  1, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "       17, 17, 17, 17,  5, 17,  5, 17,  5, 17, 18, 18, 18, 18, 18, 18, 18,\n",
              "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 20, 18, 18, 18,\n",
              "       18, 18, 18, 18,  6, 18,  6,  6,  6, 18, 18, 18, 10, 20, 21, 19, 19,\n",
              "       19, 19,  3, 25, 19, 19, 19,  1, 17, 17,  9, 19,  1, 19, 21, 19, 19,\n",
              "       19, 19, 19, 19, 20, 19,  1, 19, 19, 20, 20, 20, 20, 20, 10, 20, 20,\n",
              "       20, 20, 20, 12, 16,  2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "        8, 20,  4,  8,  8, 21, 21, 21, 23, 21, 21, 14, 21, 21, 21, 21, 22,\n",
              "       21, 23, 21, 23, 15, 23, 15, 21, 15, 16, 15, 19, 19,  7, 19, 19, 19,\n",
              "       19, 19, 19, 19, 22, 22, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "       22, 22, 22, 22, 22, 22, 22,  2, 26, 22, 16, 22, 22, 22, 20,  8,  8,\n",
              "       20, 20,  8,  8, 20, 28, 23, 23, 23, 19, 23, 23, 23, 23, 23, 23, 23,\n",
              "       23, 23, 21, 23, 23, 23, 23, 23, 23, 23, 23, 15, 23, 23, 19, 19, 19,\n",
              "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
              "       24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26,  9, 25, 25, 25,\n",
              "       13, 25, 25, 25, 14, 25, 25, 25, 10, 25, 25, 17, 25, 25, 16, 25, 25,\n",
              "       25, 25, 25, 25, 25, 15, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
              "       26, 22, 26,  2,  2, 26, 24, 22, 26, 26, 26, 26, 26, 24, 16, 24, 26,\n",
              "       26, 26, 27, 27, 27, 27,  3, 10, 27, 10,  9,  9, 10, 11,  3, 17, 27,\n",
              "        9,  9,  1,  9,  9,  9, 27, 17, 11, 27, 27, 27, 27,  9, 27, 27,  9,\n",
              "       27, 27, 27, 27,  9, 27, 28, 28, 28, 12, 11, 28,  6,  4, 28, 28, 28,\n",
              "       12, 28,  4, 28, 22, 28, 28, 26, 26, 28, 28, 28, 28, 28, 28, 28, 28,\n",
              "       28, 28, 28, 28, 28, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gNww_TKH0yl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "448625c4-9541-47c7-fb4e-95c3968468a6"
      },
      "source": [
        "0.65079*840"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "546.6636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7BbzxsHH3Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}